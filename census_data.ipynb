{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas\n",
    "\n",
    "class one_hot(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        \"\"\"does category to onehot encoding on dataframe\"\"\"\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        return pandas.get_dummies(X)\n",
    "    \n",
    "class make_sure_columns_match(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,X,testX):\n",
    "        \"\"\"Make sure that train and test set have the same columns\"\"\"\n",
    "        self.X = X\n",
    "        self.testX = testX\n",
    "        self.overlap = set(X).intersection(testX)\n",
    "    def fit(self,X,y=None):\n",
    "        return fit\n",
    "    def transform(self,X,y=None):\n",
    "        return X[list(self.overlap)].copy()\n",
    "\n",
    "    \n",
    "        \n",
    "class RemoveColumnsWithLowCorrelation(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, label_column, correlation_cutoff = .05):\n",
    "        self.correlation_cutoff = correlation_cutoff\n",
    "        self.label_column = label_column\n",
    "        self.important_correlations = []\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X,y=None):\n",
    "        if len(self.important_correlations) == 0:\n",
    "            correlation_matrix = X.corr()\n",
    "            correlation_matrix[self.label_column].sort_values(ascending=False)\n",
    "            self.important_correlations = X.columns[abs(correlation_matrix[self.label_column]) > self.correlation_cutoff]\n",
    "        return X[self.important_correlations].copy()\n",
    "        \n",
    "class filter_datapoints(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, column, conditional_func):\n",
    "        self.column = column\n",
    "        self.conditional_func = conditional_func\n",
    "    def fit(self, X, y =None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        return X[X[self.column].apply(self.conditional_func)]\n",
    "        \n",
    "            \n",
    "class split_label(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "    def fit(self, X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        return X[self.label], X.drop(self.label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data from https://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\n",
    "\n",
    "header_info = [\"age\",\n",
    "              \"class_of_worker\",\n",
    "              \"industry code\",\n",
    "              \"occupation code\",\n",
    "              \"level of education\",\n",
    "              \"wage per hour\",\n",
    "              \"entrolled in education as of last week\",\n",
    "              \"marital status\",\n",
    "              \"major industry code\",\n",
    "              \"major occupation code\",\n",
    "              \"race\",\n",
    "              \"hispanic origin\",\n",
    "              \"sex\",\n",
    "              \"member of a labor union\",\n",
    "              \"reason for unemployment\",\n",
    "              \"full or part time employment status\",\n",
    "              \"captial gains\",\n",
    "              \"capital losses\",\n",
    "              \"dividends from stocks\",\n",
    "              \"tax filler status\",\n",
    "              \"region of previous residence\",\n",
    "              \"state of previous residence\",\n",
    "              \"detailed household and family status\",\n",
    "              \"detailed household summary\",\n",
    "              \"migration code\",\n",
    "              \"migration code - change in region\",\n",
    "              \"migration code - move within region\",\n",
    "              \"live in this house one year ago\",\n",
    "              \"migration - previous resident in sunbelt\",\n",
    "              \"number of persons that worked for employer\",\n",
    "              \"family members under 18\",\n",
    "              \"country of birth father\",\n",
    "              \"country of birth mother\",\n",
    "              \"country of birth\",\n",
    "              \"citizenship\",\n",
    "              \"own business or self-employed\",\n",
    "              \"fill included questionaire for veterans administration\",\n",
    "              \"veterans benefits\",\n",
    "              \"weeks worked in the year\",\n",
    "              \"year of survey\",\n",
    "              \"income less than or greater than 50,000\",\n",
    "              \"number of years of education\"]\n",
    "\n",
    "\n",
    "my_census = pd.read_csv(\"./census-income.data\", names=header_info)\n",
    "\n",
    "test_data = pd.read_csv(\"./census-income.test\", names=header_info)\n",
    "\n",
    "#drop data if age < 18\n",
    "#census = census.drop(census[census['age'] <= 18].index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actually... just use sklearn's data splitting\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas\n",
    "\n",
    "my_census = pandas.get_dummies(my_census)\n",
    "my_test = pandas.get_dummies(test_data)\n",
    "\n",
    "filter_non_workers = lambda x : x == 0\n",
    "filter_label = 'major occupation code_ Not in universe'\n",
    "filt = filter_datapoints(column= filter_label, conditional_func=filter_non_workers)\n",
    "\n",
    "my_census = filt.transform(my_census)\n",
    "my_test = filt.transform(my_test)\n",
    "\n",
    "filter_non_workers = lambda x : x == 0\n",
    "filter_label = 'member of a labor union_ Not in universe'\n",
    "filt = filter_datapoints(column= filter_label, conditional_func=filter_non_workers)\n",
    "\n",
    "my_census = filt.transform(my_census)\n",
    "my_test = filt.transform(my_test)\n",
    "\n",
    "\n",
    "make_match = make_sure_columns_match(my_census,my_test)\n",
    "\n",
    "my_census = make_match.transform(my_census)\n",
    "my_test = make_match.transform(my_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19064, 410)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_census.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the column that we want to predict\n",
    "label = \"wage per hour\"\n",
    "\n",
    "remove_low_corr = RemoveColumnsWithLowCorrelation(label_column=label)\n",
    "\n",
    "my_low_corr_census = remove_low_corr.transform(my_census)\n",
    "my_low_corr_test = remove_low_corr.transform(my_test)\n",
    "\n",
    "split = split_label(label=label)\n",
    "\n",
    "test_label, test = split.transform(my_low_corr_test)\n",
    "census_label, census = split.transform(my_low_corr_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19064, 29)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_low_corr_census.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"The train set is {} many examples. Whereas the test set contains {} examples.\".format(len(train_set),len(test_set)))\n",
    "\n",
    "#Note that we could do stratified sampling here if we knew which categories were most important\n",
    "\n",
    "#census = train_set.copy()\n",
    "\n",
    "#drop anything with the word code\n",
    "#bad_feature = [x for x in header_info if \"code\" in x]\n",
    "\n",
    "#census = census.drop(axis=1, labels=bad_feature)\n",
    "#census = census.drop(axis=1,labels=['number of persons that worked for employer','family members under 18','year of survey','fill included questionaire for veterans administration'])\n",
    "\n",
    "#drop data if age < 18\n",
    "#census = census.drop(census[census['age'] <= 18].index)\n",
    "\n",
    "\n",
    "\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#def check_if_model_exists_and_load_or_run_and_save(model_name):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(census,census_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636.62840974371932"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "census_predictions = lin_reg.predict(test)\n",
    "\n",
    "lin_mse = mean_squared_error(test_label, census_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse\n",
    "\n",
    "#ziped = zip(lin_reg.coef_, census.columns)\n",
    "\n",
    "#zipped = sorted(ziped, reverse=True)\n",
    "#zipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's go back to the drawing board and filter out \"outliers\" ... datapoints where \"major occupation code_ Not in universe\" = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(census,census_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810.00996590733746"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_predictions2 = tree_reg.predict(test)\n",
    "tree_mse = mean_squared_error(test_label, census_predictions2)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, census, census_label, scoring = \"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"scores: \", scores)\n",
    "    print(\"mean: \", np.sqrt(-scores.mean()))\n",
    "    print(\"std: \" , scores.std())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  [-660015.02695504 -759717.73788194 -529704.19673523 -627727.77533221\n",
      " -619199.72919002 -612691.34915998 -665865.29007619 -722991.1005205\n",
      " -707960.77527305 -697010.20611485]\n",
      "mean:  812.581268996\n",
      "std:  62877.9224108\n"
     ]
    }
   ],
   "source": [
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699.0790859136921"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(census, census_label)\n",
    "forest_predict = forest_reg.predict(test)\n",
    "forest_rmse = np.sqrt(mean_squared_error(test_label,forest_predict))\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "686.53389673966205"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we will attempt a grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'n_estimators':[10,20], 'max_features':[10,20]}]\n",
    "              \n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(census, census_label)\n",
    "\n",
    "my_pred = grid_search.predict(test)\n",
    "grid_search_rmse = np.sqrt(mean_squared_error(my_pred,test_label))\n",
    "\n",
    "grid_search_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "#feature_importances\n",
    "\n",
    "column_names = census.columns\n",
    "\n",
    "important = sorted(zip(feature_importances,column_names),reverse=True)\n",
    "\n",
    "num_important_columns = 150\n",
    "my_important_column_list = []\n",
    "for i in important[:num_important_columns]:\n",
    "    my_important_column_list.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['industry code',\n",
       " 'occupation code',\n",
       " 'family members under 18',\n",
       " 'level of education_ High school graduate',\n",
       " 'level of education_ Bachelors degree(BA AB BS)',\n",
       " 'member of a labor union_ No',\n",
       " 'level of education_ Masters degree(MA MS MEng MEd MSW MBA)',\n",
       " 'major industry code_ Hospital services',\n",
       " 'number of years of education_ 50000+.',\n",
       " 'member of a labor union_ Yes',\n",
       " 'level of education_ Associates degree-occup /vocational',\n",
       " 'sex_ Female',\n",
       " 'sex_ Male',\n",
       " 'number of years of education_ - 50000.',\n",
       " 'major occupation code_ Precision production craft & repair',\n",
       " 'major industry code_ Education',\n",
       " 'class_of_worker_ Federal government',\n",
       " 'major occupation code_ Professional specialty',\n",
       " 'major occupation code_ Executive admin and managerial',\n",
       " 'major industry code_ Manufacturing-durable goods',\n",
       " 'major industry code_ Finance insurance and real estate',\n",
       " 'major occupation code_ Sales',\n",
       " 'major industry code_ Retail trade',\n",
       " 'major occupation code_ Technicians and related support',\n",
       " 'major occupation code_ Machine operators assmblrs & inspctrs',\n",
       " 'major industry code_ Construction',\n",
       " 'level of education_ Doctorate degree(PhD EdD)',\n",
       " 'major industry code_ Utilities and sanitary services']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_important_column_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this mean?\n",
    "\n",
    "Since being a member of a labor union *or* not being in a labor union *or* the status of being in a labor union unknown is the best predictor of wage -- I believe trying to filter the data to only include those greater than 18 years of age will produce more significant results.\n",
    "\n",
    "Before we do that, let's try to use a neural network model on the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1489  | total loss: \u001b[1m\u001b[32m484909.21875\u001b[0m\u001b[0m | time: 2.138s\n",
      "| SGD | epoch: 005 | loss: 484909.21875 - R2: 0.4811 -- iter: 19008/19064\n",
      "Training Step: 1490  | total loss: \u001b[1m\u001b[32m468948.50000\u001b[0m\u001b[0m | time: 3.241s\n",
      "| SGD | epoch: 005 | loss: 468948.50000 - R2: 0.5614 | val_loss: 449100.07721 - val_acc: 0.6541 -- iter: 19064/19064\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "X, Y, testX, testY = census.as_matrix(), census_label.as_matrix(), test.as_matrix(), test_label.as_matrix()\n",
    "\n",
    "\n",
    "Y= np.reshape(Y,(Y.shape[0],1))\n",
    "testY = np.reshape(testY, (testY.shape[0],1))\n",
    "\n",
    "print(\"The shape of X is: {}, while Y has the shape: {}\".format(X.shape, Y.shape))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_layer = tflearn.input_data(shape=[None,X.shape[1]])\n",
    "dense1 = tflearn.fully_connected(incoming=input_layer, n_units=40, name=\"first_layer\")\n",
    "dropout1 = tflearn.dropout(dense1, .8,name=\"dropout1\")\n",
    "dense2 = tflearn.fully_connected(dropout1,40, name=\"layer2\")\n",
    "dropout2 = tflearn.dropout(dense2, .8, name=\"dropout2\")\n",
    "last = tflearn.fully_connected(dropout2, 1, activation=\"linear\")\n",
    "\n",
    "sgd = tflearn.SGD(learning_rate=.1, lr_decay=.96, decay_step=1000)\n",
    "r2 = tflearn.metrics.R2()\n",
    "net = tflearn.regression(last, optimizer=sgd, loss = 'mean_square',metric=r2)\n",
    "\n",
    "model = tflearn.DNN(net, tensorboard_verbose=3, tensorboard_dir=\"/tmp/tensorboard\")\n",
    "model.fit(X, Y, n_epoch=5 ,run_id=\"dense_model\" , validation_set = (testX,testY), show_metric=True, snapshot_epoch=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670.14929446703525"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(model.predict(testX),testY))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
