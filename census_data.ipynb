{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas\n",
    "\n",
    "class one_hot(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        \"\"\"does category to onehot encoding on dataframe\"\"\"\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        return pandas.get_dummies(X)\n",
    "    \n",
    "class make_sure_columns_match(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,X,testX):\n",
    "        \"\"\"Make sure that train and test set have the same columns\"\"\"\n",
    "        self.X = X\n",
    "        self.testX = testX\n",
    "        self.overlap = set(X).intersection(testX)\n",
    "    def fit(self,X,y=None):\n",
    "        return fit\n",
    "    def transform(self,X,y=None):\n",
    "        return X[list(self.overlap)].copy()\n",
    "\n",
    "class remove_outliers_in_these_columns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_remove_outliers_from, absoute_z_score_limit = 3 , return_outliers = False):\n",
    "        \"\"\"fit this on the training set and remove outliers from both train and testing set\"\"\"\n",
    "        self.abs_z_score_lim = absoute_z_score_limit\n",
    "        self.check_these_columns = columns_to_remove_outliers_from\n",
    "        self.mean_and_std = []\n",
    "    def fit(self,X,y=None):\n",
    "        columns = X.columns.values.tolist()\n",
    "        for col in self.check_these_columns:\n",
    "            if col in columns:\n",
    "                self.mean_and_std[col] = [X[col].mean(),X[col].std()]\n",
    "            else:\n",
    "                print(\"This column ( {} ), is not in the database.\".format(col))\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        outliers = []\n",
    "        tempX = X.copy()\n",
    "        columns = X.columns.values.tolist()\n",
    "        for col in self.check_these_columns:\n",
    "            if col in columns:\n",
    "                mu,sigma = self.mean_and_std[col]\n",
    "                outlier_indicies = (tempX[col] - mu)/sigma > self.abs_z_score_lim\n",
    "                if return_outliers: \n",
    "                    outliers.append(tempX[outlier_indicies])\n",
    "                tempX.drop(outlier_indicies, axis = 0,inplace = True)\n",
    "        if return_outliers:\n",
    "            return outliers, tempX\n",
    "        else:\n",
    "            return tempX\n",
    "        \n",
    "class RemoveColumnsWithLowCorrelation(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, label_column, correlation_cutoff = .05):\n",
    "        self.correlation_cutoff = correlation_cutoff\n",
    "        self.label_column = label_column\n",
    "        self.important_correlations = []\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X,y=None):\n",
    "        if len(self.important_correlations) == 0:\n",
    "            correlation_matrix = X.corr()\n",
    "            correlation_matrix[self.label_column].sort_values(ascending=False)\n",
    "            self.important_correlations = X.columns[abs(correlation_matrix[self.label_column]) > self.correlation_cutoff]\n",
    "        return X[self.important_correlations].copy()\n",
    "        \n",
    "class filter_datapoints(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, column, conditional_func):\n",
    "        self.column = column\n",
    "        self.conditional_func = conditional_func\n",
    "    def fit(self, X, y =None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        return X[X[self.column].apply(self.conditional_func)]\n",
    "        \n",
    "            \n",
    "class split_label(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "    def fit(self, X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        return X[self.label], X.drop(self.label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data from https://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\n",
    "\n",
    "header_info = [\"age\",\n",
    "              \"class_of_worker\",\n",
    "              \"industry code\",\n",
    "              \"occupation code\",\n",
    "              \"level of education\",\n",
    "              \"wage per hour\",\n",
    "              \"entrolled in education as of last week\",\n",
    "              \"marital status\",\n",
    "              \"major industry code\",\n",
    "              \"major occupation code\",\n",
    "              \"race\",\n",
    "              \"hispanic origin\",\n",
    "              \"sex\",\n",
    "              \"member of a labor union\",\n",
    "              \"reason for unemployment\",\n",
    "              \"full or part time employment status\",\n",
    "              \"captial gains\",\n",
    "              \"capital losses\",\n",
    "              \"dividends from stocks\",\n",
    "              \"tax filler status\",\n",
    "              \"region of previous residence\",\n",
    "              \"state of previous residence\",\n",
    "              \"detailed household and family status\",\n",
    "              \"detailed household summary\",\n",
    "              \"migration code\",\n",
    "              \"migration code - change in region\",\n",
    "              \"migration code - move within region\",\n",
    "              \"live in this house one year ago\",\n",
    "              \"migration - previous resident in sunbelt\",\n",
    "              \"number of persons that worked for employer\",\n",
    "              \"family members under 18\",\n",
    "              \"country of birth father\",\n",
    "              \"country of birth mother\",\n",
    "              \"country of birth\",\n",
    "              \"citizenship\",\n",
    "              \"own business or self-employed\",\n",
    "              \"fill included questionaire for veterans administration\",\n",
    "              \"veterans benefits\",\n",
    "              \"weeks worked in the year\",\n",
    "              \"year of survey\",\n",
    "              \"income less than or greater than 50,000\",\n",
    "              \"number of years of education\"]\n",
    "\n",
    "\n",
    "my_census = pd.read_csv(\"./census-income.data\", names=header_info)\n",
    "\n",
    "test_data = pd.read_csv(\"./census-income.test\", names=header_info)\n",
    "\n",
    "#drop data if age < 18\n",
    "#census = census.drop(census[census['age'] <= 18].index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actually... just use sklearn's data splitting\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas\n",
    "\n",
    "my_census = pandas.get_dummies(my_census)\n",
    "my_test = pandas.get_dummies(test_data)\n",
    "\n",
    "filter_non_workers = lambda x : x > 0 & x < 1500\n",
    "filter_label = 'wage per hour'\n",
    "filt = filter_datapoints(column= filter_label, conditional_func=filter_non_workers)\n",
    "\n",
    "my_census = filt.transform(my_census)\n",
    "my_test = filt.transform(my_test)\n",
    "\n",
    "remove_outliers_from_these_columns = [\"dividends from stocks\", \"capital losses\", \"wage per hour\"]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ADD OUTLIER REMOVER CODE HERE!!!!\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "make_match = make_sure_columns_match(my_census,my_test)\n",
    "\n",
    "my_census = make_match.transform(my_census)\n",
    "my_test = make_match.transform(my_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some of the outliers in this column ( migration code ) include: \n",
      "\n",
      "1543    4856.38\n",
      "3088    5204.51\n",
      "3555    6525.17\n",
      "4822    6548.73\n",
      "6515    4877.97\n",
      "7191    6133.56\n",
      "7583    6844.27\n",
      "7664    4966.00\n",
      "7885    6254.23\n",
      "8489    5295.64\n",
      "Name: migration code, dtype: float64\n",
      "This column has a total of 110 outliers\n",
      "\n",
      "\n",
      "\n",
      "some of the outliers in this column ( dividends from stocks ) include: \n",
      "\n",
      "9190      5000\n",
      "11971     8000\n",
      "23026    10000\n",
      "25262    40000\n",
      "25913     4000\n",
      "27057     4000\n",
      "27816     6000\n",
      "28311     5000\n",
      "33869    10000\n",
      "36966     4600\n",
      "Name: dividends from stocks, dtype: int64\n",
      "This column has a total of 78 outliers\n",
      "\n",
      "\n",
      "\n",
      "some of the outliers in this column ( capital losses ) include: \n",
      "\n",
      "429     2205\n",
      "1230    1602\n",
      "2941    2001\n",
      "4042    1887\n",
      "4102    1672\n",
      "4434    1887\n",
      "4685    2206\n",
      "5185    2129\n",
      "5361    1887\n",
      "5596    1602\n",
      "Name: capital losses, dtype: int64\n",
      "This column has a total of 249 outliers\n",
      "\n",
      "\n",
      "\n",
      "some of the outliers in this column ( year of survey ) include: \n",
      "\n",
      "230     0\n",
      "2235    2\n",
      "2387    0\n",
      "2430    0\n",
      "2708    2\n",
      "2930    0\n",
      "3289    3\n",
      "4003    4\n",
      "4017    0\n",
      "4556    0\n",
      "Name: year of survey, dtype: int64\n",
      "This column has a total of 374 outliers\n",
      "\n",
      "\n",
      "\n",
      "some of the outliers in this column ( wage per hour ) include: \n",
      "\n",
      "330      5000\n",
      "1222     8000\n",
      "2103     2966\n",
      "4258     3350\n",
      "6065     3600\n",
      "8074     9000\n",
      "9196     7000\n",
      "11426    5000\n",
      "11543    3500\n",
      "13637    3000\n",
      "Name: wage per hour, dtype: int64\n",
      "This column has a total of 124 outliers\n",
      "\n",
      "\n",
      "\n",
      "some of the outliers in this column ( age ) include: \n",
      "\n",
      "9104     79\n",
      "21580    79\n",
      "23181    90\n",
      "26181    77\n",
      "35377    90\n",
      "41241    78\n",
      "56982    90\n",
      "62927    78\n",
      "78957    77\n",
      "79660    77\n",
      "Name: age, dtype: int64\n",
      "This column has a total of 29 outliers\n",
      "\n",
      "\n",
      "\n",
      "some of the outliers in this column ( captial gains ) include: \n",
      "\n",
      "10744    10520\n",
      "11247     8614\n",
      "11543    15024\n",
      "12822     8614\n",
      "17513    15024\n",
      "19586    13550\n",
      "21407    20051\n",
      "22591    13550\n",
      "23181    11678\n",
      "24027    10566\n",
      "Name: captial gains, dtype: int64\n",
      "This column has a total of 75 outliers\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#my_census.shape\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for Col in my_census.columns.values.tolist():\n",
    "    if my_census[Col].std() > 1:\n",
    "        list_of_outliers_for_col = my_census[((my_census[Col] - my_census[Col].mean())/ my_census[Col].std()).abs() > 3]\n",
    "        if len(list_of_outliers_for_col) >= 10:\n",
    "            print(\"some of the outliers in this column ( {} ) include: \\n\".format(Col))\n",
    "            print(list_of_outliers_for_col[Col][:10])\n",
    "            print(\"This column has a total of {} outliers\".format(len(list_of_outliers_for_col)))\n",
    "            print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the column that we want to predict\n",
    "label = \"wage per hour\"\n",
    "\n",
    "remove_low_corr = RemoveColumnsWithLowCorrelation(label_column=label)\n",
    "\n",
    "my_low_corr_census = remove_low_corr.transform(my_census)\n",
    "my_low_corr_test = remove_low_corr.transform(my_test)\n",
    "\n",
    "split = split_label(label=label)\n",
    "\n",
    "test_label, test = split.transform(my_low_corr_test)\n",
    "census_label, census = split.transform(my_low_corr_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "my_low_corr_census.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"The train set is {} many examples. Whereas the test set contains {} examples.\".format(len(train_set),len(test_set)))\n",
    "\n",
    "#Note that we could do stratified sampling here if we knew which categories were most important\n",
    "\n",
    "#census = train_set.copy()\n",
    "\n",
    "#drop anything with the word code\n",
    "#bad_feature = [x for x in header_info if \"code\" in x]\n",
    "\n",
    "#census = census.drop(axis=1, labels=bad_feature)\n",
    "#census = census.drop(axis=1,labels=['number of persons that worked for employer','family members under 18','year of survey','fill included questionaire for veterans administration'])\n",
    "\n",
    "#drop data if age < 18\n",
    "#census = census.drop(census[census['age'] <= 18].index)\n",
    "\n",
    "\n",
    "\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#def check_if_model_exists_and_load_or_run_and_save(model_name):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(census,census_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "census_predictions = lin_reg.predict(test)\n",
    "\n",
    "lin_mse = mean_squared_error(test_label, census_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse\n",
    "\n",
    "ziped = zip(lin_reg.coef_, census.columns)\n",
    "\n",
    "zipped = sorted(ziped, reverse=True)\n",
    "zipped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's go back to the drawing board and filter out \"outliers\" ... datapoints where \"major occupation code_ Not in universe\" = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(census,census_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_predictions2 = tree_reg.predict(test)\n",
    "tree_mse = mean_squared_error(test_label, census_predictions2)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, census, census_label, scoring = \"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"scores: \", scores)\n",
    "    print(\"mean: \", np.sqrt(-scores.mean()))\n",
    "    print(\"std: \" , scores.std())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(census, census_label)\n",
    "forest_predict = forest_reg.predict(test)\n",
    "forest_rmse = np.sqrt(mean_squared_error(test_label,forest_predict))\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will attempt a grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'n_estimators':[10,20], 'max_features':[10,20]}]\n",
    "              \n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(census, census_label)\n",
    "\n",
    "my_pred = grid_search.predict(test)\n",
    "grid_search_rmse = np.sqrt(mean_squared_error(my_pred,test_label))\n",
    "\n",
    "grid_search_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "#feature_importances\n",
    "\n",
    "column_names = census.columns\n",
    "\n",
    "important = sorted(zip(feature_importances,column_names),reverse=True)\n",
    "\n",
    "num_important_columns = 150\n",
    "my_important_column_list = []\n",
    "for i in important[:num_important_columns]:\n",
    "    my_important_column_list.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_important_column_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this mean?\n",
    "\n",
    "Since being a member of a labor union *or* not being in a labor union *or* the status of being in a labor union unknown is the best predictor of wage -- I believe trying to filter the data to only include those greater than 18 years of age will produce more significant results.\n",
    "\n",
    "Before we do that, let's try to use a neural network model on the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "X, Y, testX, testY = census.as_matrix(), census_label.as_matrix(), test.as_matrix(), test_label.as_matrix()\n",
    "\n",
    "\n",
    "Y= np.reshape(Y,(Y.shape[0],1))\n",
    "testY = np.reshape(testY, (testY.shape[0],1))\n",
    "\n",
    "print(\"The shape of X is: {}, while Y has the shape: {}\".format(X.shape, Y.shape))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_layer = tflearn.input_data(shape=[None,X.shape[1]])\n",
    "dense1 = tflearn.fully_connected(incoming=input_layer, n_units=40, name=\"first_layer\")\n",
    "dropout1 = tflearn.dropout(dense1, .8,name=\"dropout1\")\n",
    "dense2 = tflearn.fully_connected(dropout1,X.shape[1], name=\"layer2\")\n",
    "dropout2 = tflearn.dropout(dense2, .8, name=\"dropout2\")\n",
    "dense3 = tflearn.fully_connected(dropout2, X.shape[1], activation=\"relu\")\n",
    "dropout3 = tflearn.dropout(dense3, .8, name=\"dropout3\")\n",
    "dense4 = tflearn.fully_connected(dropout3, X.shape[1], activation=\"relu\")\n",
    "last = tflearn.fully_connected(dense4, 1, activation=\"linear\")\n",
    "\n",
    "sgd = tflearn.SGD(learning_rate=.1, lr_decay=.96, decay_step=1000)\n",
    "r2 = tflearn.metrics.R2()\n",
    "net = tflearn.regression(last, optimizer=sgd, loss = 'mean_square',metric=r2)\n",
    "\n",
    "model = tflearn.DNN(net, tensorboard_verbose=3, tensorboard_dir=\"/tmp/tensorboard\")\n",
    "model.fit(X, Y, n_epoch=2 ,run_id=\"dense_model\" , validation_set = (testX,testY), show_metric=True, snapshot_epoch=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(model.predict(testX),testY))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
